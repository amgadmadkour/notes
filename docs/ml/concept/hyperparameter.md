# Hyperparameter

A hyperparameter is a parameter that is set by the practitioner before the learning process begins. This is in contrast to model parameters which are learned from the data during the training process.

## Examples

1. **Learning Rate:** Controls how much to change the model in response to the estimated error each time the model weights are updated.
2. **Number of Epochs:** The number of times the learning algorithm will work through the entire training dataset.
3. **Batch Size:** The number of training examples utilized in one iteration.
4. **Number of Hidden Layers and Units:** In neural networks, this determines the depth and complexity of the model.
5. **Regularization Parameters:** Such as L1 or L2 regularization, which help prevent overfitting by penalizing large weights.
6. **Momentum:** Used in optimization algorithms to accelerate gradients vectors in the right directions, thus leading to faster converging.
7. **Number of Trees in a Random Forest:** Determines the number of decision trees in the ensemble.