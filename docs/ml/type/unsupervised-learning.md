# Unsupervised Learning

- Unsupervised learning uses **unlabeled data** for training.
- This is particularly useful in problems where it is difficult to obtain labeled data.
- Unsupervised learning algorithms are useful for discovering patterns in data.
- The goal of unsupervised learning is use a feature vector as input and either outputs a feature vector or a label/value. 

## Use Cases

- ***Clustering*** algorithm takes a feature vector as input and outputs a label. 
- ***Dimensionality reduction*** algorithms take a feature vector as input and output a feature vector with less features.
- ***Anomaly detection*** algorithms take a feature vector as input and output is a real number indicating the degree of anomaly.

## Examples

- Clustering:
      - [k-Means](../algorithm/unsupervised/k-means.md)
      - [Hierarchical Clustering](../algorithm/unsupervised/hierarchical-clustering.md)
      - [DBScan](../algorithm/unsupervised/dbscan.md)
- Anomaly Detection:
      - [Isolation Forest](../algorithm/unsupervised/isolation-forest.md)
      - [One-class SVM](../algorithm/unsupervised/one-class-svm.md)
- Dimensionality Reduction:
      - [Principal Component Analysis](../algorithm/unsupervised/principal-component-analysis.md)
      - [t-Distributed Stochastic Neighbor Embedding](../algorithm/unsupervised/t-distributed-stochastic-neighbor-embedding.md)
      - [Kernel PCA](../algorithm/unsupervised/kernel-pca.md)
      - [Locally Linear Embedding](../algorithm/unsupervised/locally-linear-embedding.md)
- Association Rule Learning:
      - [Apriori](../algorithm/unsupervised/apriori.md)
      - [Eclat](../algorithm/unsupervised/eclat.md)
